{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- 2023_fashion_trends.csv (Provided with the Project)\n",
    "#### Reason: \n",
    "This source contains data from events from the year 2023,so the gpt-3.5-turbo-instruct model would not know about this data because it was never trained on it.Additionally, it contains references from different data sources with descriptive content and the names of the articles, which makes it would make it easier to create specific prompts that could return different answers. Lastly, this dataset is not likely to change, so my chatbot will not break as it would with wikipedia articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define Constants\n",
    "OPEN_AI_KEY = ''\n",
    "MAX_TOKENS = 150\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = OPEN_AI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5bab2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_wrangle(file_path):\n",
    "    # Read File and save data to variable\n",
    "    df = pd.read_csv(file_path , header=0)\n",
    "\n",
    "    # Combine Data into a single column named Text\n",
    "    df['text'] =  df['Source'] + ': '+ df['Trends'] + ' | ' + df['URL']\n",
    "    # Remove old columns\n",
    "    df.drop(['URL','Source', 'Trends'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "def generate_embeddings(df: pd.DataFrame, output_csv_file: str, embedding_model_name: str):\n",
    "    \"\"\"Generating Embeddings\n",
    "    We'll use the `Embedding`\n",
    "    tooling from OpenAI [documentation here](https://platform.openai.com/docs/guides/embeddings/embeddings)\n",
    "    to create vectors representing each row of our custom dataset.\"\"\"\n",
    "\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        # Send text data to OpenAI model to get embeddings\n",
    "        response = openai.Embedding.create(\n",
    "            input=df.iloc[i:i + batch_size][\"text\"].tolist(),\n",
    "            engine=embedding_model_name\n",
    "        )\n",
    "\n",
    "        # Add embeddings to list\n",
    "        embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "    # Add embeddings list to dataframe\n",
    "    df[\"embeddings\"] = embeddings\n",
    "\n",
    "    # In order to avoid having to run that code again in the future, we'll save the generated embeddings as a CSV file.\n",
    "    df.to_csv(output_csv_file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Embedding and saving to CSV\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_FILE = './data/embeddings.csv'\n",
    "DATASET_SOURCE_FILE = './data/2023_fashion_trends.csv'\n",
    "try:\n",
    "    data_f = pd.read_csv(EMBEDDINGS_FILE, index_col=0)\n",
    "    data_f[\"embeddings\"] = data_f[\"embeddings\"].apply(eval).apply(np.array)\n",
    "except:\n",
    "    print(\"Creating Embedding and saving to CSV\")\n",
    "    # Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "    wrangled_dataset = load_and_wrangle(DATASET_SOURCE_FILE)\n",
    "    # Generating Embeddings\n",
    "    dataset_w_embeddings = generate_embeddings(wrangled_dataset, EMBEDDINGS_FILE, EMBEDDING_MODEL_NAME)\n",
    "else:\n",
    "    print('\"Embedding is loaded to CSV\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
